# Avery Yen
Hi, I'm Avery. I'm a longtime product engineer turned AI researcher investigating adversarial robustness and evaluation methods for frontier language models. I'm a Research Assistant at the [National Deep Inference Fabric](https://ndif.us) (NDIF) with David Bau, a member of MIT AI Alignment (MAIA), and pursuing my MS in Computer Science at Northeastern University.

Before transitioning to AI research, I spent over 12 years as a software engineer, with my longest tenure at Pivotal Labs.

## Research Interests

**AI Adversarial Evaluation**

I believe that understanding how AI systems learn, reason, and fail is essential for building technology we can trust. My work focuses on evaluation methodologies that reveal adversarial behaviors under messy, real-life situations.

Current projects explore deception detection in multi-agent games, quantization effects on model alignment, and live rankings for frontier model capabilities.

## Selected Projects
- Multi-Agent Social Deception Arena (project lead): Evaluation platform for testing strategic deception and agent profiling capabilities in frontier LLMs using social deduction games. Live leaderboard continuously benchmarks ChatGPT, Claude, DeepSeek, and other models.

- [Showing Our Work: Training Gemma3 1B To Reason](https://www.kaggle.com/competitions/google-tunix-hackathon/writeups/showing-your-work-training-gemma-1b-to-reason): Independent project to develop an efficient, near-SotA post-training recipe for 1B language models under limited computation budgets (under judgement) [notebook here](https://www.kaggle.com/code/averyyen/tunix-model-reasoning-training/notebook)

- [National Deep Inference Fabric](https://ndif.us): The NSF National Deep Inference Fabric (NDIF) is a research computing project that enables researchers and students to perform mechanistic interpretability research on models, with sizes up to a 405B parameter open-weight model.

## Contact

Feel free to find me on [LinkedIn](https://linkedin.com/in/averyyen/).
